{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config.get('IAM_USER', 'AWS_ACCESS_KEY_ID')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config.get('IAM_USER', 'AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ab3d70b18748:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8a307a9898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+---------------+----------------+--------------------+--------------------+------------------+--------------------+---------+----+\n",
      "|num_songs|         artist_id|artist_latitude|artist_longitude|     artist_location|         artist_name|           song_id|               title| duration|year|\n",
      "+---------+------------------+---------------+----------------+--------------------+--------------------+------------------+--------------------+---------+----+\n",
      "|        1|ARDR4AC1187FB371A1|           null|            null|                    |Montserrat Caball...|SOBAYLL12A8C138AF9|Sono andati? Fing...|511.16363|   0|\n",
      "|        1|AREBBGV1187FB523D2|           null|            null|         Houston, TX|Mike Jones (Featu...|SOOLYAZ12A6701F4A6|Laws Patrolling (...|173.66159|   0|\n",
      "|        1|ARMAC4T1187FB3FA4C|       40.82624|       -74.47995|   Morris Plains, NJ|The Dillinger Esc...|SOBBUGU12A8C13E95D|Setting Fire to S...|207.77751|2004|\n",
      "|        1|ARPBNLO1187FB3D52F|       40.71455|       -74.00712|        New York, NY|            Tiny Tim|SOAOIBZ12AB01815BE|I Hold Your Hand ...| 43.36281|2000|\n",
      "|        1|ARNF6401187FB57032|       40.79086|       -73.96644|New York, NY [Man...|   Sophie B. Hawkins|SONWXQJ12A8C134D94|The Ballad Of Sle...|  305.162|1994|\n",
      "+---------+------------------+---------------+----------------+--------------------+--------------------+------------------+--------------------+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_data='data/song_data/*/*/*/*.json'\n",
    "song_schema = StructType([\n",
    "        StructField('num_songs', IntegerType()),\n",
    "        StructField('artist_id', StringType()),\n",
    "        StructField('artist_latitude', DoubleType()),\n",
    "        StructField('artist_longitude', DoubleType()),\n",
    "        StructField('artist_location', StringType()),\n",
    "        StructField('artist_name', StringType()),\n",
    "        StructField('song_id', StringType()),\n",
    "        StructField('title', StringType()),\n",
    "        StructField('duration', DoubleType()),\n",
    "        StructField('year', IntegerType())\n",
    "    ])\n",
    "df = spark.read.json(song_data, schema=song_schema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Schema for Song Play Analysis\n",
    "\n",
    "Using the song and log datasets, you'll need to create a star schema optimized for queries on song play analysis. This includes the following tables.\n",
    "Fact Table\n",
    "\n",
    "    songplays - records in log data associated with song plays i.e. records with page NextSong\n",
    "        songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent\n",
    "\n",
    "Dimension Tables\n",
    "\n",
    "    users - users in the app\n",
    "        user_id, first_name, last_name, gender, level\n",
    "    songs - songs in music database\n",
    "        song_id, title, artist_id, year, duration\n",
    "    artists - artists in music database\n",
    "        artist_id, name, location, lattitude, longitude\n",
    "    time - timestamps of records in songplays broken down into specific units\n",
    "        start_time, hour, day, week, month, year, weekday\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOBAYLL12A8C138AF9|Sono andati? Fing...|ARDR4AC1187FB371A1|   0|511.16363|\n",
      "|SOOLYAZ12A6701F4A6|Laws Patrolling (...|AREBBGV1187FB523D2|   0|173.66159|\n",
      "|SOBBUGU12A8C13E95D|Setting Fire to S...|ARMAC4T1187FB3FA4C|2004|207.77751|\n",
      "|SOAOIBZ12AB01815BE|I Hold Your Hand ...|ARPBNLO1187FB3D52F|2000| 43.36281|\n",
      "|SONWXQJ12A8C134D94|The Ballad Of Sle...|ARNF6401187FB57032|1994|  305.162|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_columns = ['song_id', 'title', 'artist_id', 'year' ,'duration']\n",
    "df_songs = df.select(songs_columns)\n",
    "print(df_songs.count())\n",
    "df_songs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songs.createOrReplaceTempView('songs_sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|year|count(year)|\n",
      "+----+-----------+\n",
      "|   0|         43|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_with_year_zero = spark.sql('''\n",
    "SELECT year, count(year) FROM songs_sql\n",
    "GROUP BY year HAVING year = 0\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songs.write.partitionBy('year').parquet('parquet/songs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+---------+----+\n",
      "|           song_id|               title|         artist_id| duration|year|\n",
      "+------------------+--------------------+------------------+---------+----+\n",
      "|SOUQQEA12A8C134B1B|           High Tide|ARIG6O41187B988BDD| 228.5971|   0|\n",
      "|SOLLHMX12AB01846DC|   The Emperor Falls|AR1Y2PT1187FB5B9CE|484.62322|   0|\n",
      "|SOPEGZN12AB0181B3D|Get Your Head Stu...|AREDL271187FB40F44| 45.66159|   0|\n",
      "|SOBBXLX12A58A79DDA|Erica (2005 Digit...|AREDBBQ1187B98AFF5|138.63138|   0|\n",
      "|SOTCKKY12AB018A141|Sonnerie lalaleul...|ARGSAFR1269FB35070| 29.54404|   0|\n",
      "+------------------+--------------------+------------------+---------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "parquet_songs = spark.read.parquet('parquet/songs')\n",
    "parquet_songs.show(5)\n",
    "print(parquet_songs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+---------------+--------+----------+\n",
      "|         artist_id|        name|       location|latitude| longitude|\n",
      "+------------------+------------+---------------+--------+----------+\n",
      "|ARPBNLO1187FB3D52F|    Tiny Tim|   New York, NY|40.71455| -74.00712|\n",
      "|ARBEBBY1187B9B43DB|   Tom Petty|Gainesville, FL|    null|      null|\n",
      "|AR0IAWL1187B9A96D0|Danilo Perez|         Panama|  8.4177| -80.11278|\n",
      "|ARMBR4Y1187B9990EB|David Martin|California - SF|37.77916|-122.42005|\n",
      "|ARD0S291187B9B7BF5|     Rated R|           Ohio|    null|      null|\n",
      "+------------------+------------+---------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.createOrReplaceTempView('parquet_db')\n",
    "artists_data = spark.sql('''\n",
    "    SELECT DISTINCT artist_id, artist_name as name, artist_location as location, \n",
    "           artist_latitude as latitude, artist_longitude as longitude\n",
    "    FROM parquet_db\n",
    "''')\n",
    "artists_data.show(5)\n",
    "#df.selectExpr(artist_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+--------+----------+\n",
      "|         artist_id|           name|       location|latitude| longitude|\n",
      "+------------------+---------------+---------------+--------+----------+\n",
      "|ARPBNLO1187FB3D52F|       Tiny Tim|   New York, NY|40.71455| -74.00712|\n",
      "|ARXR32B1187FB57099|            Gob|               |    null|      null|\n",
      "|AROGWRA122988FEE45|Christos Dantis|               |    null|      null|\n",
      "|ARBGXIG122988F409D|     Steel Rain|California - SF|37.77916|-122.42005|\n",
      "|AREVWGE1187B9B890A|     Bitter End|      Noci (BA)| -13.442|  -41.9952|\n",
      "+------------------+---------------+---------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_columns = ['artist_id',\n",
    "                  'artist_name as name',\n",
    "                  'artist_location as location', \n",
    "                  'artist_latitude as latitude',\n",
    "                  'artist_longitude as longitude']\n",
    "\n",
    "df.selectExpr(artist_columns).dropDuplicates().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_data.write.parquet('parquet/artists/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "LOG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Harmonia', auth='Logged In', firstName='Ryan', gender='M', itemInSession=0, lastName='Smith', length=655.77751, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Sehr kosmisch', status=200, ts=1542241826796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26'),\n",
       " Row(artist='The Prodigy', auth='Logged In', firstName='Ryan', gender='M', itemInSession=1, lastName='Smith', length=260.07465, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='The Big Gundown', status=200, ts=1542242481796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26'),\n",
       " Row(artist='Train', auth='Logged In', firstName='Ryan', gender='M', itemInSession=2, lastName='Smith', length=205.45261, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Marry Me', status=200, ts=1542242741796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data = 'data/logs_data/*.json'\n",
    "# two partitins in s3 datas (year and month). But no paertitions here.\n",
    "df_log = spark.read.json(log_data)\n",
    "df_log.take(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get only NextSong events"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
